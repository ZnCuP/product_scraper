name: Scrape Products

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Install Playwright browsers
        run: python -m playwright install --with-deps

      - name: Create data directory
        run: mkdir -p product_scraper/data

      - name: Run product scraper
        run: |
          cd product_scraper
          python main.py

      - name: Upload new product data as artifact
        uses: actions/upload-artifact@v4
        with:
          name: product-data-${{ github.run_id }}
          path: product_scraper/data/

      - name: Configure Git for committing
        run: |
          git config user.name "GitHub Actions"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Check for changes to commit
        id: git_check
        run: |
          git add product_scraper/data/
          if git diff --cached --exit-code; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Commit and Push changes
        if: steps.git_check.outputs.has_changes == 'true'
        run: |
          git commit -m "feat: Update product data and check for new items (Automated)"
          git push origin main